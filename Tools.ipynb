{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f36a1cd",
   "metadata": {},
   "source": [
    "**LLM Strengths:**\n",
    "\n",
    "Reasoning Capability: LLMs can understand and break down questions to determine how to respond (ability to think).\n",
    "\n",
    "Language Generation: LLMs generate word-by-word responses based on reasoning (ability to speak).\n",
    "\n",
    "**LLM Limitations:**\n",
    "\n",
    "LLMs cannot perform tasks beyond thinking and generating content, as they lack the ability to execute actions (no hands or legs analogy).\n",
    "\n",
    "Examples of tasks LLMs cannot do:\n",
    "\n",
    "Fetch live weather data.\n",
    "\n",
    "Reliably solve complex math problems (basic arithmetic is possible but not guaranteed for complex tasks).\n",
    "\n",
    "Call external APIs (e.g., post a tweet on Twitter).\n",
    "\n",
    "Run code or interact with databases.\n",
    "\n",
    "*Analogy*: An LLM is like a human body with a brain (to think and speak) but no hands or legs (to act)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ce2b2d",
   "metadata": {},
   "source": [
    "# TOOLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492d626f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Definition of Tools:**\n",
    "\n",
    "Tools are mechanisms that give LLMs the ability to execute tasks (providing hands and legs).\n",
    "\n",
    "Technically, tools are Python functions with task-specific logic, packaged to interact with LLMs.\n",
    "\n",
    "Example: A tool for booking train tickets on IRCTC’s website can be created and connected to an LLM. When asked to book a ticket, the LLM uses the tool to perform the task.\n",
    "\n",
    "Power of Tools: The more tools you add to an LLM, the more types of tasks it can perform.\n",
    "\n",
    "**Types of Tools in LangChain**\n",
    "\n",
    "**Built-in Tools:**\n",
    "Pre-built tools provided by the LangChain team for common use cases, requiring no coding.\n",
    "\n",
    "Examples:\n",
    "DuckDuckGo Search: Perform web searches using the DuckDuckGo search engine.\n",
    "\n",
    "Wikipedia Query Run: Search Wikipedia and retrieve summarized content.\n",
    "\n",
    "Python REPL Tool: Run raw Python code (e.g., calculate factorial reliably).\n",
    "\n",
    "Gmail Send Message Tool: Send emails via Gmail.\n",
    "\n",
    "\n",
    "Advantages: Production-ready, minimal setup, no need to write function logic.\n",
    "\n",
    "Use Case: Useful for common tasks like web searching, code execution, or database querying.\n",
    "\n",
    "https://python.langchain.com/docs/integrations/tools/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e9c2fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b02014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stay here for real-time updates on breaking news from India and across the world that you can\\'t miss: India\\'s forex reserves rise by $ 1.983 billion to $ 688.129 billion during the week ended ... \"Officers and officials of CGI Shanghai, friends of India and members of Indian diaspora led by Consul General @PratikMathur1 offered deepest and heartfelt condolences to the victims of the #PahalgamTerroristAttack today in the Consulate,\" stated a post by the Consulate on social media platform X, dated April 30. India News | Latest India News | Read latest and breaking news from India. Today\\'s top India news headlines, news on Indian politics, elections, government, business, technology, and Bollywood. Pakistan might issue a formal diplomatic notice to India in the wake of the suspension of Indus Water Treaty, news agency PTI reported citing a media report on Friday. The decision to issue the notice was taken after discussions between Pakistan\\'s ministries of Foreign Affairs, Law, and Water Resources, Express News reported quoting sources. Business News News IndiaIndia makes 3 BOLD moves against Pakistan in single day after Pahalgam attack - Check details More Less First Published : 3 May 2025, 09:32 PM IST'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = DuckDuckGoSearchRun()\n",
    "search.invoke(\"Latest news in india today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f47934e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duckduckgo_search\n",
      "A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query.\n",
      "{'query': {'description': 'search query to look up', 'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "print(search.name)\n",
    "print(search.description)\n",
    "print(search.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134cd042",
   "metadata": {},
   "source": [
    "**Custom Tools:**\n",
    "Tools created by users for specific use cases not covered by built-in tools.\n",
    "\n",
    "When to Create Custom Tools:\n",
    "\n",
    "Calling Proprietary APIs: Integrating with a company’s internal APIs (e.g., a travel booking API for a MakeMyTrip-like application).\n",
    "\n",
    "Encapsulating Business Logic: Implementing unique logic specific to an application.\n",
    "\n",
    "Interacting with Databases/Products: Enabling an LLM to interact with a custom database or app.\n",
    "\n",
    "Example: Building a tool for an agent to perform bookings by interacting with a company’s database via APIs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab9c57a",
   "metadata": {},
   "source": [
    "**Methods to Create Custom Tools**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e0d9cd",
   "metadata": {},
   "source": [
    "\n",
    "**Using the @tool Decorator (Simplest Method)**:\n",
    "Process (Three Steps):\n",
    "Write a Function: Create a Python function with the task logic (e.g., a function to multiply two numbers).\n",
    "Add a docstring (highly recommended) to describe what the function does, as it helps the LLM understand the tool’s purpose.\n",
    "\n",
    "Add Type Hints: Specify input and output types (e.g., int for inputs a and b, and int for the return value).\n",
    "Type hints are optional but recommended to clarify data expectations for the LLM.\n",
    "\n",
    "Apply @tool Decorator: Add the @tool decorator above the function to make it a special function that can interact with an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "329f1ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(a: int,b: int)->int:\n",
    "    '''Multiplication of two numbers'''\n",
    "    return a*b\n",
    "\n",
    "multiply.invoke({'a':3,'b':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c758f546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply\n",
      "Multiplication of two numbers\n",
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4b620b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'Multiplication of two numbers', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b'], 'title': 'multiply', 'type': 'object'}\n"
     ]
    }
   ],
   "source": [
    "print(multiply.args_schema.model_json_schema())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91474443",
   "metadata": {},
   "source": [
    "**Using the StructuredTool Class with Pydantic (More Strict Method)**:\n",
    "Definition: A structured tool enforces a strict input schema using a Pydantic model, making it more robust for production.\n",
    "\n",
    "Advantages:\n",
    "Enforces stricter input constraints using Pydantic, making it suitable for production-ready applications.\n",
    "\n",
    "Separates function logic from schema definition for better organization.\n",
    "\n",
    "Use Case: Preferred for complex applications requiring robust input validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "354eec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel,Field\n",
    "class Multiply(BaseModel):\n",
    "    a : int = Field(description='First Number',required=True)\n",
    "    b : int = Field(description=\"Second Number\",required=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4c11d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_func(a: int, b: int) -> int:\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75129951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import StructuredTool\n",
    "multiply_tool = StructuredTool.from_function(\n",
    "    func = multiply_func,\n",
    "    name = \"multiply\",\n",
    "    description = \"Multiplication of two numbers\",\n",
    "    args_schema = Multiply\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8161e4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply_tool.invoke({'a':3, 'b':3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d9c59e",
   "metadata": {},
   "source": [
    "**Using the BaseTool Class (Most Customizable Method)**:\n",
    "Definition: The BaseTool class is the abstract base class for all LangChain tools, defining the core structure and interface. All tools (built-in or custom) inherit from it.\n",
    "\n",
    "Advantages:\n",
    "Offers deep customization, including support for asynchronous tools.\n",
    "\n",
    "Ideal for production-level applications with complex requirements or concurrency needs.\n",
    "\n",
    "Drawback: More complex than the @tool or StructuredTool methods.\n",
    "\n",
    "Use Case: Used when advanced customization or asynchronous functionality is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6dbcdfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool\n",
    "from typing import Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1d1fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arg schema using pydantic\n",
    "\n",
    "class MultiplyInput(BaseModel):\n",
    "    a: int = Field(required=True, description=\"The first number to add\")\n",
    "    b: int = Field(required=True, description=\"The second number to add\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad647d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiplyTool(BaseTool):\n",
    "    name: str = \"multiply\"\n",
    "    description: str = \"Multiply two numbers\"\n",
    "\n",
    "    args_schema: Type[BaseModel] = MultiplyInput\n",
    "\n",
    "    def _run(self, a: int, b: int) -> int:\n",
    "        return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d773f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiplyTool().invoke({'a':6, 'b':3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b74603b",
   "metadata": {},
   "source": [
    "**Recommendation:**\n",
    "For most scenarios (80-90%), the @tool decorator is sufficient and simplest.\n",
    "\n",
    "For production-ready applications, consider StructuredTool or BaseTool for stricter constraints or advanced features.\n",
    "\n",
    "Explore LangChain’s documentation for additional methods and examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf90f9d2",
   "metadata": {},
   "source": [
    "### TOOLKIT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37977505",
   "metadata": {},
   "source": [
    "**Toolkits**\n",
    "Definition: A toolkit is a collection of related tools that serve a common purpose, packaged together for convenience and reusability.\n",
    "\n",
    "Purpose:\n",
    "Organize multiple tools that are logically related.\n",
    "\n",
    "Enhance reusability across different applications.\n",
    "\n",
    "Example:\n",
    "Google Drive Toolkit: Combines tools like:\n",
    "Upload files to Google Drive.\n",
    "\n",
    "Search files on Google Drive.\n",
    "\n",
    "Read files from Google Drive.\n",
    "\n",
    "These tools are related as they all interact with Google Drive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5a9f0c",
   "metadata": {},
   "source": [
    "**Built-in Toolkits**: LangChain provides prebuilt toolkits for common use cases.\n",
    "\n",
    "Benefits:\n",
    "Simplifies access to multiple related tools.\n",
    "\n",
    "Promotes reusability across applications.\n",
    "\n",
    "Note: Toolkits are a small but useful concept for organizing tools efficiently.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ea86ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "# Custom tools\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bfb86aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MathToolkit:\n",
    "    def get_tools(self):\n",
    "        return [add, multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b88255f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add => Add two numbers\n",
      "multiply => Multiply two numbers\n"
     ]
    }
   ],
   "source": [
    "toolkit = MathToolkit()\n",
    "tools = toolkit.get_tools()\n",
    "\n",
    "for tool in tools:\n",
    "    print(tool.name, \"=>\", tool.description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3448fa",
   "metadata": {},
   "source": [
    "**Why Tools Are Critical for Agents:**\n",
    "\n",
    "The combination of LLMs (for reasoning) and tools (for action) creates an agent.\n",
    "\n",
    "Tools are as essential as LLMs for building agents, making the concept of tools foundational.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a6201c",
   "metadata": {},
   "source": [
    "# TOOL CALLING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da976fe8",
   "metadata": {},
   "source": [
    "\n",
    "**Definition:** Tool calling is the process where an LLM decides during a conversation or task that a specific tool is needed and generates a structured output containing the tool’s name and required input arguments.\n",
    "\n",
    "**Purpose:** Enables LLMs to suggest which tool to use and how to use it, allowing task execution without the LLM directly performing the action.\n",
    "\n",
    "**Key Points:**\n",
    "LLMs do not execute tools; they only recommend the tool and provide input arguments.\n",
    "\n",
    "Actual tool execution is handled by LangChain and the programmer, ensuring control and safety.\n",
    "\n",
    "Example: For a query like “What’s 8 * 7?”, the LLM identifies a multiplication tool, specifies inputs (e.g., a=8, b=7), and suggests invoking it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c421ba5a",
   "metadata": {},
   "source": [
    "### Tool Binding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090073b3",
   "metadata": {},
   "source": [
    "\n",
    "**Definition:** Tool binding is the process of registering tools with an LLM, so the LLM knows which tools are available, what they do, and how to invoke them.\n",
    "\n",
    "**Purpose:**\n",
    "Informs the LLM about available tools.\n",
    "\n",
    "Provides tool descriptions to clarify their functionality.\n",
    "\n",
    "Specifies the input schema (format) each tool expects.\n",
    "\n",
    "**Outcome:** After binding, the LLM can intelligently select and suggest tools during conversations based on their descriptions and input requirements.\n",
    "\n",
    "**Limitation:** Not all LLMs support tool binding; only specific models have this capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "708b68d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001F84F065F40>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001F84F067110>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model=\"Llama3-8b-8192\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2334d4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def mul(a:int,b:int) -> int:\n",
    "    \"Multiplication of two integer numbers\"\n",
    "    return a*b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62e0bc62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='multiply', description='Multiply two numbers', args_schema=<class 'langchain_core.utils.pydantic.multiply'>, func=<function multiply at 0x000001F83809BB00>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc070d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Multiply two numbers',\n",
       " 'properties': {'a': {'title': 'A', 'type': 'integer'},\n",
       "  'b': {'title': 'B', 'type': 'integer'}},\n",
       " 'required': ['a', 'b'],\n",
       " 'title': 'multiply',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.args_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c47d645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools([mul])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "15d3ac0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001F84F065F40>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001F84F067110>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2494e9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001F84F065F40>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001F84F067110>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'mul', 'description': 'Multiplication of two integer numbers', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d718e571",
   "metadata": {},
   "source": [
    "### Tool Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72130f9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Tool Calling Process**\n",
    "Scenario:\n",
    "An LLM with access to a tool (e.g., multiplication tool) is queried.\n",
    "\n",
    "For general queries (e.g., “How are you?”), the LLM responds directly without tool involvement.\n",
    "\n",
    "For task-specific queries (e.g., “Multiply 3 by 10”), the LLM:\n",
    "Checks available tools.\n",
    "\n",
    "Identifies a relevant tool (e.g., multiplication tool).\n",
    "\n",
    "Generates a structured output with:\n",
    "Tool name (e.g., multiply).\n",
    "\n",
    "Input arguments (e.g., {\"a\": 3, \"b\": 10}).\n",
    "\n",
    "Output: The LLM produces a tool call (not a text response), which includes the tool name and arguments, avoiding direct execution to maintain safety.\n",
    "\n",
    "**Key Insight:** Tool calling is an advisory process; the LLM suggests the tool and inputs but does not execute it, leaving execution to the programmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0ebb4c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"I'm doing well, thanks for asking!\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 1866, 'total_tokens': 1876, 'completion_time': 0.008333333, 'prompt_time': 0.233369311, 'queue_time': -0.28559678099999997, 'total_time': 0.241702644}, 'model_name': 'Llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None} id='run--19069624-1461-4c92-859a-03943f988d4a-0' usage_metadata={'input_tokens': 1866, 'output_tokens': 10, 'total_tokens': 1876}\n"
     ]
    }
   ],
   "source": [
    "res = llm_with_tools.invoke(\"Hi, How are you?\")\n",
    "print(res) # Here LLM produced content on its own capabilities, No tools are involved here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214f4a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_rrtk', 'function': {'arguments': '{\"a\":3,\"b\":5}', 'name': 'mul'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 925, 'total_tokens': 997, 'completion_time': 0.06, 'prompt_time': 0.115587023, 'queue_time': 0.08821108000000001, 'total_time': 0.175587023}, 'model_name': 'Llama3-8b-8192', 'system_fingerprint': 'fp_dadc9d6142', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--dc370bd0-064a-4e0f-aacf-db11993646d3-0' tool_calls=[{'name': 'mul', 'args': {'a': 3, 'b': 5}, 'id': 'call_rrtk', 'type': 'tool_call'}] usage_metadata={'input_tokens': 925, 'output_tokens': 72, 'total_tokens': 997}\n"
     ]
    }
   ],
   "source": [
    "res = llm_with_tools.invoke(\"What is multiplication of three and five?\")\n",
    "print(res) # Here LLM produced empty content, instead suggested to call multiply tool (see additional_kwargs,tool_calls in response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aba21d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'mul',\n",
       "  'args': {'a': 3, 'b': 5},\n",
       "  'id': 'call_rrtk',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ea27ba",
   "metadata": {},
   "source": [
    "### Tool Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd5003a",
   "metadata": {},
   "source": [
    "**Definition:** Tool execution is the step where the programmer invokes the suggested tool using the input arguments provided by the LLM during tool calling.\n",
    "\n",
    "**Process:**\n",
    "The LLM’s tool call output (e.g., tool name and arguments) is used to invoke the tool.\n",
    "\n",
    "The tool runs its logic and returns a result.\n",
    "\n",
    "The result is packaged as a tool message, a special message type containing the tool’s output.\n",
    "\n",
    "**Role in Workflow:**\n",
    "Completes the task execution initiated by the LLM’s suggestion.\n",
    "\n",
    "The tool message can be sent back to the LLM to provide context for generating a final response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cbc03843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='15', name='multiply', tool_call_id='call_rrtk')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = multiply.invoke(res.tool_calls[0])\n",
    "output # Here output is ToolMessage unlike AIMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b085455",
   "metadata": {},
   "source": [
    "\n",
    "**Conversation History and Context**\n",
    "\n",
    "Concept: A conversation history is maintained to track the sequence of interactions, including:\n",
    "Human Message: User’s query (e.g., “Multiply 3 by 10”).\n",
    "\n",
    "AI Message: LLM’s response, which may include tool calls.\n",
    "\n",
    "Tool Message: Result of tool execution.\n",
    "\n",
    "Purpose: The history provides full context to the LLM, enabling it to generate a final answer by combining user queries, tool suggestions, and execution results.\n",
    "\n",
    "**Workflow:**\n",
    "\n",
    "User sends a query (human message).\n",
    "\n",
    "LLM responds with a tool call (AI message).\n",
    "\n",
    "Programmer executes the tool, generating a tool message.\n",
    "\n",
    "All messages are sent back to the LLM, which generates a final response (e.g., “The product of 3 and 10 is 30”)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "21c2e7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c8e83f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what is multiplication of three and four?\"\n",
    "message = HumanMessage(question)\n",
    "history = []\n",
    "history.append(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "52951536",
   "metadata": {},
   "outputs": [],
   "source": [
    "response1 = llm_with_tools.invoke(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d3940d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.append(response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b90b77f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='what is multiplication of three and four?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_czpe', 'function': {'arguments': '{\"a\":3,\"b\":4}', 'name': 'mul'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 79, 'prompt_tokens': 925, 'total_tokens': 1004, 'completion_time': 0.065833333, 'prompt_time': 0.135056495, 'queue_time': 0.088369968, 'total_time': 0.200889828}, 'model_name': 'Llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--7c96bfc9-2445-4dac-a528-69e439d3fb10-0', tool_calls=[{'name': 'mul', 'args': {'a': 3, 'b': 4}, 'id': 'call_czpe', 'type': 'tool_call'}], usage_metadata={'input_tokens': 925, 'output_tokens': 79, 'total_tokens': 1004})]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a586015e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='12', name='mul', tool_call_id='call_czpe')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2 = mul.invoke(response1.tool_calls[0])\n",
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "de6ea618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='what is multiplication of three and four?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_czpe', 'function': {'arguments': '{\"a\":3,\"b\":4}', 'name': 'mul'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 79, 'prompt_tokens': 925, 'total_tokens': 1004, 'completion_time': 0.065833333, 'prompt_time': 0.135056495, 'queue_time': 0.088369968, 'total_time': 0.200889828}, 'model_name': 'Llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--7c96bfc9-2445-4dac-a528-69e439d3fb10-0', tool_calls=[{'name': 'mul', 'args': {'a': 3, 'b': 4}, 'id': 'call_czpe', 'type': 'tool_call'}], usage_metadata={'input_tokens': 925, 'output_tokens': 79, 'total_tokens': 1004})]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4083c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.append(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "75a45f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='what is multiplication of three and four?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_czpe', 'function': {'arguments': '{\"a\":3,\"b\":4}', 'name': 'mul'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 79, 'prompt_tokens': 925, 'total_tokens': 1004, 'completion_time': 0.065833333, 'prompt_time': 0.135056495, 'queue_time': 0.088369968, 'total_time': 0.200889828}, 'model_name': 'Llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--7c96bfc9-2445-4dac-a528-69e439d3fb10-0', tool_calls=[{'name': 'mul', 'args': {'a': 3, 'b': 4}, 'id': 'call_czpe', 'type': 'tool_call'}], usage_metadata={'input_tokens': 925, 'output_tokens': 79, 'total_tokens': 1004}),\n",
       " ToolMessage(content='12', name='mul', tool_call_id='call_czpe')]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d3b3eaf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The result is 12.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 992, 'total_tokens': 999, 'completion_time': 0.005833333, 'prompt_time': 0.124763105, 'queue_time': 0.068485642, 'total_time': 0.130596438}, 'model_name': 'Llama3-8b-8192', 'system_fingerprint': 'fp_dadc9d6142', 'finish_reason': 'stop', 'logprobs': None}, id='run--e10bc70b-37d1-4f9e-b879-490603a82e2e-0', usage_metadata={'input_tokens': 992, 'output_tokens': 7, 'total_tokens': 999})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a3cc37",
   "metadata": {},
   "source": [
    "\n",
    "**Injected Tool Arguments**\n",
    "**Definition:** A mechanism to mark specific tool inputs as “injected,” meaning the LLM does not provide their values during tool calling, and the programmer supplies them later.\n",
    "\n",
    "**Purpose:**\n",
    "Ensures sequential tool execution by preventing the LLM from prematurely setting inputs (e.g., conversion rate) based on outdated knowledge.\n",
    "\n",
    "Allows the programmer to use outputs from one tool (e.g., conversion rate) as inputs for another.\n",
    "\n",
    "Example:\n",
    "In the convert tool, the conversion rate is marked as an injected tool argument.\n",
    "\n",
    "During tool calling, the LLM specifies only the base currency value (e.g., 10 USD) and leaves the conversion rate blank.\n",
    "\n",
    "The programmer fetches the conversion rate from the get_conversion_factor tool and injects it into the convert tool’s arguments before execution.\n",
    "\n",
    "Benefit: Maintains logical dependency between tools, ensuring accurate results (e.g., real-time conversion rate is used).\n",
    "\n",
    "Is This an AI Agent?\n",
    "Question: Does the currency conversion application qualify as an AI agent?\n",
    "\n",
    "Answer: No, it is not a true AI agent.\n",
    "\n",
    "Reason:\n",
    "AI Agent Characteristics: An AI agent is autonomous, capable of breaking down problems, deciding steps, and executing tasks independently without manual intervention.\n",
    "\n",
    "Application Limitations: The currency conversion application relies on the programmer to:\n",
    "Manually execute tools.\n",
    "\n",
    "Manage conversation history.\n",
    "\n",
    "Inject tool arguments.\n",
    "\n",
    "This manual involvement contrasts with an agent’s ability to autonomously handle the entire workflow.\n",
    "\n",
    "Agent Example:\n",
    "For “Convert 10 USD to INR,” an AI agent would:\n",
    "Recognize the need for a conversion rate and call get_conversion_factor.\n",
    "\n",
    "Use the fetched rate to call convert with appropriate inputs.\n",
    "\n",
    "Deliver the final result without programmer intervention.\n",
    "\n",
    "The agent would handle all steps autonomously, unlike the application, which requires coded logic for each step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415e8c37",
   "metadata": {},
   "source": [
    "**Agent Definition:** An AI agent is an LLM-powered system that can autonomously think, decide, and take actions using external tools and APIs to achieve a goal.\n",
    "\n",
    "Agent Capabilities:\n",
    "Reasoning and Decision-Making: Provided by the LLM (thinking step-by-step to solve a problem).\n",
    "\n",
    "Action Execution: Enabled by tools (performing tasks based on reasoning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6fb28b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
